{"cells":[{"cell_type":"markdown","metadata":{"id":"y00RfkU5gl3e"},"source":["# pip install"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBfYaCjEgokt"},"outputs":[],"source":["pip install gymnasium\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttq6_9qDgp-c"},"outputs":[],"source":["pip install \"stable-baselines3[extra]>=2.0.0a4\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6x7QilC85No"},"outputs":[],"source":["import numpy as np\n","\n","import gymnasium as gym\n","from gymnasium import spaces\n","\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.env_util import make_vec_env, SubprocVecEnv, DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy"]},{"cell_type":"markdown","metadata":{"id":"XlZPhtptcf9v"},"source":["## set reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfbdcxuNcker"},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","import os\n","os.environ['PYTHONASHSEED'] = '0'\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","\n","seed = 0\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"markdown","source":["# Learning Rate Func"],"metadata":{"id":"Ly-x3gpq9yWX"}},{"cell_type":"code","source":["\n","def linear_schedule(initial_value):\n","\n","    if isinstance(initial_value, str):\n","        initial_value = float(initial_value)\n","\n","    def func(progress):\n","\n","        return progress * initial_value\n","\n","    return func"],"metadata":{"id":"G1WxvxqS901I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pEsAU3iFchK7"},"source":["# Ranking Func"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zM7C0pJLRwhY"},"outputs":[],"source":["    def load_topic_target_location(topic_id,target_recall):\n","      ## load data\n","\n","      vector_size = 100 # vector size to feed NN\n","\n","      all_vectors = [[-1]*vector_size for i in range(vector_size)]\n","\n","      target_location = -1 # initial\n","\n","\n","      n_docs = len(doc_rank_dic[topic_id])  # total n. docs in topic\n","      rel_list = rank_rel_dic[topic_id]  # list binary rel of ranked docs\n","\n","      # get points\n","      windows = make_windows(vector_size, n_docs)\n","\n","      window_size = windows[0][1]\n","\n","      # calculate points that will be used to fit curve\n","      rel_cnt,rel_rate, n_samp_docs_current = get_rel_cnt_rate(windows, vector_size, rel_list)\n","\n","\n","      n_rel = sum(rel_cnt)\n","      prev = sum(rel_cnt)/n_docs\n","\n","\n","      #update all vector with all possible examined states\n","      for i in range(vector_size):\n","        all_vectors[i][0:i+1] = rel_rate[0:i+1] # update examined part\n","\n","        #calculate target recall stopping pos\n","        #mark only 1st recall achieved stopping position\n","        if (sum(rel_cnt[0:i+1]) / sum(rel_cnt)) >= target_recall and target_location == -1:\n","          target_location = i\n","\n","\n","      return topic_id, n_docs, n_rel, prev, target_location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2BEFPXMBfgpR"},"outputs":[],"source":["def get_rel_cnt_rate(windows, window_size, rel_list):\n","\n","    # x-values are the cnt at which relevant documents occur in the window\n","    x = [np.sum(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n","\n","    # y-values are the rate at which relevant documents occur in the window\n","    y = [np.sum(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n","    y = [y_i/window_size for y_i in y]\n","\n","\n","    # z-values are the cnt of documents in the window\n","    z = [len(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n","\n","\n","    # convert lists to numpy arrays\n","    x = np.array(x)\n","    y = np.array(y)\n","    z= np.array(z)\n","    return (x,y,z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re1zRU2ZfCmb"},"outputs":[],"source":["%matplotlib inline\n","\n","# IMPORT LIBRARIES\n","import sys\n","import os\n","import numpy as np\n","import pandas as pd\n","import math\n","from scipy.optimize import curve_fit\n","import random\n","import glob\n","import subprocess\n","import matplotlib.pyplot as plt\n","from scipy.integrate import simps\n","from scipy.stats import norm\n","import os\n","\n","import scipy\n","\n","import seaborn as sns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZ_VXtt5dYfZ"},"outputs":[],"source":["# Ensure that Python looks in correct place for local modules\n","DIR = '/xxhome/' # replace with utils home directory\n","\n","\n","sys.path.append(DIR)\n","\n","# IMPORT OWN FUNCTIONS\n","from utils.read_data_fns import *\n","from utils.eval_fns import *\n","from utils.inhomogeneous_pp_fns import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6kwyfWZvYVs"},"outputs":[],"source":["# LOAD TOPIC RELEVANCE DATA\n","def load_rel_data(qrels):\n","  qrel_fname =  os.path.join(DIR, qrels)\n","  with open(qrel_fname, 'r') as infile:\n","      qrels_data = infile.readlines()\n","  query_rel_dic = make_rel_dic(qrels_data) # make dictionary of list of docids relevant to each queryid\n","\n","  return qrel_fname, query_rel_dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-_sA4fUvpJh"},"outputs":[],"source":["# LOAD RUN DATA\n","def load_run_data(run):\n","  run_fname = os.path.join(DIR, run)\n","  with open(run_fname, 'r') as infile:\n","    run_data = infile.readlines()\n","  doc_rank_dic = make_rank_dic(run_data)  # make dictionary of ranked docids for each queryid\n","  rank_rel_dic = make_rank_rel_dic(query_rel_dic,doc_rank_dic) # make dic of list relevances of ranked docs for each queryid\n","\n","  return doc_rank_dic, rank_rel_dic"]},{"cell_type":"code","source":["df_all_targets = pd.DataFrame()\n","DRL_DIR = '/xx/' # replace with working directory\n"],"metadata":{"id":"iV2VUWqzvrIu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QjCDeTJ5UKiW"},"source":["# TAREnv class\n","\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","import gymnasium as gym\n","from gymnasium import spaces\n","\n","SELECTED_TOPICS = [] # keep track of all randomly selected topics\n","\n","class TAREnv(gym.Env):\n","\n","\n","\n","    def __init__(self, target_recall, topics_list = None, topic_id= None, size=100 , render_mode=None):\n","        self.size = size  # The size of the ranking relv vector\n","\n","        #observation is 1D np array size array of relv vector\n","        self.observation_space = spaces.Box(-1,  1, shape=(size,), dtype=np.float32)\n","\n","        #  actions, corresponding to \"next\", \"stop\"\n","        self.action_space = spaces.Discrete(2)\n","\n","        # Set up properties\n","        self.done = False\n","        self.reward = 0\n","        self.hit, self.miss = 0, 0\n","\n","\n","        # Set up the TAR\n","        self.vector_size = size\n","\n","\n","        # current position and stop position\n","        self._agent_location = 0\n","        self._target_location = -1 #dummy value\n","\n","        # keep predicted recall so far\n","        self.recall = 0\n","        self.target_recall = target_recall\n","\n","        # topic data\n","        self.topics_list = topics_list\n","        self.topic_id = topic_id # for single env\n","\n","\n","        #for vec env\n","        if topic_id is None:\n","          # select a new random topic\n","          while True:\n","            t = random.choice(topics_list)\n","            if t not in SELECTED_TOPICS:\n","              SELECTED_TOPICS.append(t)\n","              self.topic_id = t\n","              break\n","\n","          # use same ordered list of topics across diffreent runs\n","          if TRAINING:\n","            global SELECTED_TOPICS_ORDERERD_INDEX\n","            self.topic_id = SELECTED_TOPICS_ORDERERD[SELECTED_TOPICS_ORDERERD_INDEX]\n","            SELECTED_TOPICS_ORDERERD_INDEX += 1\n","        else:\n","           self.topic_id = topic_id # for single env\n","\n","\n","        self.n_docs = 0\n","        self.rel_cnt = []\n","        self.rel_rate = []\n","        self.n_samp_docs = 0\n","        self.n_samp_docs_after_target = 0\n","        self.n_samp_docs_current = []\n","        self.rel_list = []\n","        self.all_vectors = []\n","\n","        # Define constants for clear code\n","        self.NEXT = 0\n","        self.STOP = 1\n","\n","\n","        self.load_data_flag = True\n","        self.load_data(self.topic_id)\n","\n","        self.first_step_flag = True\n","\n","\n","\n","\n","    def load_data(self, topic_id):\n","\n","      all_vectors = [[-1]*self.vector_size for i in range(self.vector_size)]\n","      topic_id = self.topic_id\n","\n","      n_docs = len(doc_rank_dic[topic_id])  # total n. docs in topic\n","      rel_list = rank_rel_dic[topic_id]  # list binary rel of ranked docs\n","\n","      # get points\n","      windows = make_windows(self.vector_size, n_docs)\n","\n","      window_size = windows[0][1]\n","\n","      # calculate relv vector points (batches)\n","      rel_cnt,rel_rate, n_samp_docs_current = get_rel_cnt_rate(windows, self.vector_size, rel_list)\n","\n","      self.n_docs = n_docs\n","      self.rel_cnt = rel_cnt\n","      self.rel_rate = rel_rate\n","      self.n_samp_docs_current = n_samp_docs_current\n","      self.rel_list = rel_list\n","\n","\n","      #update all vector with all possible examined states\n","      for i in range(self.vector_size):\n","        all_vectors[i][0:i+1] = rel_rate[0:i+1] # update examined part\n","\n","        #calculate target recall stopping pos\n","        #mark only 1st recall achieved stopping position\n","        if (sum(self.rel_cnt[0:i+1]) / sum(self.rel_cnt)) >= self.target_recall and self._target_location == -1:\n","          self._target_location = i\n","\n","\n","      self.all_vectors = all_vectors\n","\n","\n","    def _get_obs(self):\n","        return  np.array(self.all_vectors[self._agent_location], dtype=np.float32)\n","\n","\n","    def _get_info(self):\n","        return {\n","                \"topic_id\": self.topic_id,\n","                \"recall\": round((self.recall),3),\n","                \"cost\": round(((self._agent_location +1)/100),3), # each vec pos == 1% of collection\n","                \"e_cost\": round((((self._agent_location +1) - self._target_location)/100) / (1-(self._target_location/100)),3), #updated\n","                \"distance\": (self._agent_location - self._target_location),\n","                \"agent\": (self._agent_location),\n","                \"target\": (self._target_location),\n","                \"agent_vector\": np.array(self.all_vectors[self._agent_location]),\n","                \"terminal_observation\": np.array(self.all_vectors[self._target_location])} # target_vector named terminal_observation needed for SB3 vec_env\n","\n","    def reset(self,seed=0):\n","\n","        # re-load data 1st time for vec_env\n","        if self.load_data_flag:\n","          self.load_data(self.topic_id)\n","          self.load_data_flag = False\n","\n","        #initialize all pos info in reset (i.e. recall, n_samp_docs)\n","        # always start at first position of relv vector (1st batch size)\n","        self._agent_location = 0\n","        self.n_samp_docs =  sum(self.n_samp_docs_current[0:self._agent_location+1])\n","        self.n_samp_docs_after_target =  sum(self.n_samp_docs_current[self._target_location:self._agent_location+1])\n","\n","        self.recall = sum(self.rel_cnt[0:self._agent_location+1]) / sum(self.rel_cnt)\n","\n","        state = self.all_vectors[self._agent_location]\n","\n","\n","        observation = self._get_obs()\n","        info = self._get_info()\n","\n","        return observation, info\n","\n","\n","    def step(self, action):\n","        truncated = False\n","        terminated = False\n","\n","        if self._agent_location >= self.vector_size-1:\n","          self.done = True\n","          truncated = True\n","\n","\n","        if self._agent_location >= self.vector_size-2 and action == self.NEXT:\n","          self.done = True\n","          truncated = True\n","\n","        if action == self.STOP:\n","            terminated = True\n","\n","\n","        if action == self.NEXT:\n","            #update TAR vars to next pos vars\n","            if self.first_step_flag:\n","              self._agent_location = self._agent_location # dont move next, examine 1st portion at pos [0]\n","              self.first_step_flag = False\n","            else:\n","              self._agent_location += 1 # move to next portion (examined)\n","\n","            self.n_samp_docs =  sum(self.n_samp_docs_current[0:self._agent_location+1])\n","            self.n_samp_docs_after_target =  sum(self.n_samp_docs_current[self._target_location:self._agent_location+1])\n","            self.recall = sum(self.rel_cnt[0:self._agent_location+1]) / sum(self.rel_cnt)\n","\n","        observation = self._get_obs()\n","        info = self._get_info()\n","\n","\n","        # R(t) = 1 - (t-1) / target_step, if t ≤ target_step , -1 * (t - target_step) / (total_steps - target_step), if t > target_step\n","\n","        #to get more easy readable formula\n","        reward_target_location = self._target_location+1\n","        reward_agent_location = self._agent_location+1\n","\n","        # misses/reach target_recall\n","        if reward_agent_location <= reward_target_location:\n","          self.reward = 1 - ((reward_agent_location-1) / reward_target_location)\n","\n","        # overachieves target_recall\n","        elif reward_agent_location > reward_target_location:\n","            self.reward = -1 * (reward_agent_location - reward_target_location) / (self.vector_size - reward_target_location)\n","\n","        return observation, self.reward, terminated, truncated, info\n","\n","\n","\n","\n","    def render(self):\n","        # we dont need render\n","        return\n","\n","\n","    def close(self):\n","        # we dont need close\n","        return\n","\n"],"metadata":{"id":"RpIO2YndUKiY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y5NLBfXJUKic"},"source":["## Hyperparameter Settings"]},{"cell_type":"code","source":["TRAINING = True\n","total_runs = 10\n","\n","# Train the agent\n","ent_coef = 0.01\n","\n","gamma = 0.99\n","learning_rate_initial = 0.0001\n","\n","learning_rate = linear_schedule(learning_rate_initial)\n","clip_range=0.2\n","\n","n_steps = 100\n","batch_size = 100\n","n_epochs =8\n","\n","model_name = 'reward_1-1_'\n","learning_rate_type = '_linear_schedule'+str(learning_rate_initial)\n","\n","learning_rate_type = '_lr_static'+str(learning_rate_initial)\n","\n","total_timesteps = 100_000\n","\n","tensorboard_log = '/logs/'\n","\n"],"metadata":{"id":"OWMc64-9UKic"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Target 0.9"],"metadata":{"id":"bb5t0nnWvrIw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"trwC5TvOvrIx"},"outputs":[],"source":["target_recall = 0.9 # replace with other target recall level"]},{"cell_type":"markdown","metadata":{"id":"9021EE_uvrIx"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIYgrwPsvrIx"},"outputs":[],"source":["TRAINING = True"]},{"cell_type":"code","source":["training_dataset = 'CLEF'\n"],"metadata":{"id":"Xq06AKLsmzai"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQNtQe-CvrIy"},"source":["#### sort topics by target location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abjOyIwavrIy"},"outputs":[],"source":["\n","dataset_name = 'CLEF2017'\n","\n","\n","qrels = \"data/qrels/CLEF2017_qrels.txt\"\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/clef2017_training_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0GYWsXNvrIy"},"outputs":[],"source":["#remove topic CD008760 last element, contains 64 items only, < 100 vector size\n","topics_list= topics_list[:-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPXvdDZyvrIz"},"outputs":[],"source":["topics_info = []\n","\n","for t in topics_list:\n","  topic_id, n_docs, n_rel, prev, target_location = load_topic_target_location(t,target_recall)\n","  print(topic_id, n_docs, n_rel, round(prev,3), target_location)\n","  topics_info.append([topic_id, n_docs, n_rel, prev, target_location])\n","\n","topics_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUOvCF3ZvrIz"},"outputs":[],"source":["# import pandas as pd\n","import pandas as pd\n","\n","\n","df = pd.DataFrame(topics_info, columns=['topic_id', 'n_docs', 'n_rel', 'prev', 'target_location'])\n","df = df.sort_values(by=['target_location'])\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AMp4j8MvrIz"},"outputs":[],"source":["sorted_target_loc_topics = list(df['topic_id'])\n","sorted_target_loc_topics"]},{"cell_type":"markdown","metadata":{"id":"T2YVvKbNvrI0"},"source":["####ordered topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGT5clWFvrI0"},"outputs":[],"source":["TRAINING = True\n","\n","SELECTED_TOPICS_ORDERERD = sorted_target_loc_topics\n","SELECTED_TOPICS_ORDERERD_INDEX = 0\n","\n","# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","train_size = len(topics_list)\n","vec_env_train = vec_env"]},{"cell_type":"markdown","metadata":{"id":"zwRZ2csfvrI0"},"source":["#### PPO"]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"KFn_jJTMvrI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","tb_log_name = model_name+\"_\"+training_dataset+\"_ppo_gma_\"+str(gamma)+\"_nsteps\"+str(n_steps)+\"_btch\"+str(batch_size)+\"_timesteps_\"+str(total_timesteps)+ \"_ent_coef\"+str(ent_coef)+ learning_rate_type +\"_n_epochs\"+str(n_epochs)+\"_target\"+str(target_recall)\n","\n","model = PPO(\n","    policy = 'MlpPolicy',\n","    env = vec_env_train,\n","    n_steps = n_steps,\n","    batch_size = batch_size,\n","    n_epochs = n_epochs,\n","    gamma = gamma,\n","    gae_lambda = 0.98,\n","    ent_coef = ent_coef,\n","    verbose=1,\n","    learning_rate = learning_rate,\n","    seed=0,\n","    tensorboard_log= tensorboard_log)\n","\n","model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n","\n","\n","model.save(tensorboard_log+'model_'+tb_log_name)\n","\n","\n"],"metadata":{"id":"TmvIXFQLvrI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir \"$tensorboard_log\"\n"],"metadata":{"id":"uAH0YW8zvrI2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O0K6vm3EvrI5"},"source":["## TESTING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RD8taXFIvrI5"},"outputs":[],"source":["TRAINING = False"]},{"cell_type":"markdown","metadata":{"id":"6dafJeCGvrI5"},"source":["###clef2017"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISshquTgvrI6"},"outputs":[],"source":["\n","dataset_name = 'CLEF2017'\n","\n","\n","qrels = \"data/qrels/CLEF2017_qrels.txt\"\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/clef2017_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KexHxgvvrI6"},"outputs":[],"source":["# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtkW9xzQvrI6"},"outputs":[],"source":["test_size = len(topics_list)\n","vec_env_test = vec_env"]},{"cell_type":"markdown","metadata":{"id":"jhBug1u_wGMs"},"source":["#### TAR Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQz44x48wGM1"},"outputs":[],"source":["\n","df = pd.DataFrame()\n","df_all_runs = pd.DataFrame()\n","\n","for run in range(total_runs):\n","\n","  # Test the trained agent\n","  vec_env_test = vec_env\n","  obs = vec_env_test.reset()\n","  test_steps = 100\n","\n","\n","  n_env = test_size\n","  agent=0\n","  target=0\n","  agent_vector=[]\n","  terminal_observation=[]\n","\n","  topics = []\n","  recalls = []\n","  costs=[]\n","  e_costs = []\n","  reliabilities = []\n","  rewards = []\n","  distances = []\n","  differences = []\n","  targets = []\n","  run_cnts = []\n","\n","  for eID in range(test_size):\n","\n","    env = vec_env_test.envs[eID]\n","    obs, info = env.reset()\n","\n","    for step in range(test_steps):\n","      action, _ = model.predict(obs, deterministic=False) # predict all next steps\n","      obs, reward, done, trun,info = env.step(action)\n","\n","\n","      if done or trun:\n","                  topic_id = info['topic_id']\n","                  recall = info['recall']\n","                  cost = info['cost']\n","                  e_cost =  ((info['agent'] - info['target']) / (100-info['target']))\n","                  distance = info['distance']\n","\n","                  agent = info['agent']\n","                  target = info['target']\n","                  agent_vector = info['agent_vector']\n","                  terminal_observation = info['terminal_observation']\n","\n","                  difference = target_recall - recall\n","\n","                  reliability = 1 if recall >= target_recall else 0\n","                  topics.append(topic_id)\n","                  recalls.append(recall)\n","                  costs.append(cost)\n","                  e_costs.append(e_cost)\n","                  reliabilities.append(reliability)\n","                  rewards.append(reward)\n","                  distances.append(distance)\n","                  targets.append(target)\n","                  run_cnts.append(run)\n","                  differences.append(difference)\n","\n","                  df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n","                  columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n","\n","                  df = pd.concat([df_tmp])\n","\n","                  df.groupby('Topic').mean()\n","\n","                  break\n","\n","  display(df)\n","  df.groupby('Topic').mean()\n","  df_all_runs = pd.concat([df_all_runs, df])\n","\n","df_all_runs['Model'] = model_name\n","df_all_runs['Model_settings'] = tb_log_name\n","df_all_runs['Target_Recall'] = target_recall\n","df_all_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SnVP48swGM1"},"outputs":[],"source":["display(df_all_runs.groupby('Topic').mean())\n","display(df_all_runs.groupby('Topic').std())\n"]},{"cell_type":"markdown","metadata":{"id":"Gubag6SqwGM1"},"source":["#### df_all_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZbmZaUSwGM2"},"outputs":[],"source":["\n","df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n","\n","\n","display(df_all_targets)\n","\n","df_all_targets.describe()"]},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))\n","display(df_all_targets.groupby(['Target_Recall','Dataset']).std().round(3))"],"metadata":{"id":"obDrqj6ywGM2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0qE1pq7vrI_"},"source":["###clef2018"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjWOuwE6vrJA"},"outputs":[],"source":["\n","dataset_name = 'CLEF2018'\n","\n","\n","qrels = \"data/qrels/CLEF2018_qrels_LiKs.txt\" # use the same qrel list as their rankings\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/clef2018_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpxW7H4MvrJB"},"outputs":[],"source":["# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MosHTrphvrJB"},"outputs":[],"source":["test_size = len(topics_list)\n","vec_env_test = vec_env"]},{"cell_type":"markdown","metadata":{"id":"wuTDj0W2wWye"},"source":["#### TAR Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5v_QYNjxwWyf"},"outputs":[],"source":["\n","df = pd.DataFrame()\n","df_all_runs = pd.DataFrame()\n","\n","for run in range(total_runs):\n","\n","  # Test the trained agent\n","  vec_env_test = vec_env\n","  obs = vec_env_test.reset()\n","  test_steps = 100\n","\n","\n","  n_env = test_size\n","  agent=0\n","  target=0\n","  agent_vector=[]\n","  terminal_observation=[]\n","\n","  topics = []\n","  recalls = []\n","  costs=[]\n","  e_costs = []\n","  reliabilities = []\n","  rewards = []\n","  distances = []\n","  differences = []\n","  targets = []\n","  run_cnts = []\n","\n","  for eID in range(test_size):\n","\n","    env = vec_env_test.envs[eID]\n","    obs, info = env.reset()\n","\n","    for step in range(test_steps):\n","      action, _ = model.predict(obs, deterministic=False) # predict all next steps\n","      obs, reward, done, trun,info = env.step(action)\n","\n","\n","      if done or trun:\n","                  topic_id = info['topic_id']\n","                  recall = info['recall']\n","                  cost = info['cost']\n","                  e_cost =  ((info['agent'] - info['target']) / (100-info['target']))\n","                  distance = info['distance']\n","\n","                  agent = info['agent']\n","                  target = info['target']\n","                  agent_vector = info['agent_vector']\n","                  terminal_observation = info['terminal_observation']\n","\n","                  difference = target_recall - recall\n","\n","                  reliability = 1 if recall >= target_recall else 0\n","                  topics.append(topic_id)\n","                  recalls.append(recall)\n","                  costs.append(cost)\n","                  e_costs.append(e_cost)\n","                  reliabilities.append(reliability)\n","                  rewards.append(reward)\n","                  distances.append(distance)\n","                  targets.append(target)\n","                  run_cnts.append(run)\n","                  differences.append(difference)\n","\n","                  df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n","                  columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n","\n","                  df = pd.concat([df_tmp])\n","\n","                  df.groupby('Topic').mean()\n","\n","                  break\n","\n","  display(df)\n","  df.groupby('Topic').mean()\n","  df_all_runs = pd.concat([df_all_runs, df])\n","\n","df_all_runs['Model'] = model_name\n","df_all_runs['Model_settings'] = tb_log_name\n","df_all_runs['Target_Recall'] = target_recall\n","df_all_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAbMOIr5wWyf"},"outputs":[],"source":["display(df_all_runs.groupby('Topic').mean())\n","display(df_all_runs.groupby('Topic').std())\n"]},{"cell_type":"markdown","metadata":{"id":"xSe33FehwWyg"},"source":["#### df_all_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brGT0e9CwWyg"},"outputs":[],"source":["\n","df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n","\n","\n","display(df_all_targets)\n","\n","df_all_targets.describe()"]},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))\n","display(df_all_targets.groupby(['Target_Recall','Dataset']).std().round(3))"],"metadata":{"id":"HnTgvIYcwWyg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sVrxyUwMvrJF"},"source":["###clef2019"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8oyykHyvrJG"},"outputs":[],"source":["\n","dataset_name = 'CLEF2019'\n","\n","\n","qrels = \"data/qrels/CLEF2019_qrels_LiKs.txt\" # use the same qrel list as their rankings\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/clef2019_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HAXfzS79vrJG"},"outputs":[],"source":["#remove topic CD012164 last element, contains 61 items only, < 100 vector size\n","topics_list= topics_list[:-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAdCPfZvvrJG"},"outputs":[],"source":["# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3W3TCs-WvrJH"},"outputs":[],"source":["test_size = len(topics_list)\n","vec_env_test = vec_env"]},{"cell_type":"markdown","metadata":{"id":"EQTp13XvwihX"},"source":["#### TAR Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPyDpeudwihi"},"outputs":[],"source":["\n","df = pd.DataFrame()\n","df_all_runs = pd.DataFrame()\n","\n","for run in range(total_runs):\n","\n","  # Test the trained agent\n","  vec_env_test = vec_env\n","  obs = vec_env_test.reset()\n","  test_steps = 100\n","\n","\n","  n_env = test_size\n","  agent=0\n","  target=0\n","  agent_vector=[]\n","  terminal_observation=[]\n","\n","  topics = []\n","  recalls = []\n","  costs=[]\n","  e_costs = []\n","  reliabilities = []\n","  rewards = []\n","  distances = []\n","  differences = []\n","  targets = []\n","  run_cnts = []\n","\n","  for eID in range(test_size):\n","\n","    env = vec_env_test.envs[eID]\n","    obs, info = env.reset()\n","\n","    for step in range(test_steps):\n","      action, _ = model.predict(obs, deterministic=False) # predict all next steps\n","      obs, reward, done, trun,info = env.step(action)\n","\n","\n","      if done or trun:\n","                  topic_id = info['topic_id']\n","                  recall = info['recall']\n","                  cost = info['cost']\n","                  e_cost =  ((info['agent'] - info['target']) / (100-info['target']))\n","                  distance = info['distance']\n","\n","                  agent = info['agent']\n","                  target = info['target']\n","                  agent_vector = info['agent_vector']\n","                  terminal_observation = info['terminal_observation']\n","\n","                  difference = target_recall - recall\n","\n","                  reliability = 1 if recall >= target_recall else 0\n","                  topics.append(topic_id)\n","                  recalls.append(recall)\n","                  costs.append(cost)\n","                  e_costs.append(e_cost)\n","                  reliabilities.append(reliability)\n","                  rewards.append(reward)\n","                  distances.append(distance)\n","                  targets.append(target)\n","                  run_cnts.append(run)\n","                  differences.append(difference)\n","\n","                  df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n","                  columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n","\n","                  df = pd.concat([df_tmp])\n","\n","                  df.groupby('Topic').mean()\n","\n","                  break\n","\n","  display(df)\n","  df.groupby('Topic').mean()\n","  df_all_runs = pd.concat([df_all_runs, df])\n","\n","df_all_runs['Model'] = model_name\n","df_all_runs['Model_settings'] = tb_log_name\n","df_all_runs['Target_Recall'] = target_recall\n","df_all_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjJBr2GDwihi"},"outputs":[],"source":["display(df_all_runs.groupby('Topic').mean())\n","display(df_all_runs.groupby('Topic').std())\n"]},{"cell_type":"markdown","metadata":{"id":"m9YTjSUzwihi"},"source":["#### df_all_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sr2MSvOkwihi"},"outputs":[],"source":["\n","df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n","\n","\n","display(df_all_targets)\n","\n","df_all_targets.describe()"]},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))\n","display(df_all_targets.groupby(['Target_Recall','Dataset']).std().round(3))"],"metadata":{"id":"J6L4WsoZwihj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okU3R-cavrJX"},"source":["##TREC-TR"]},{"cell_type":"markdown","metadata":{"id":"vdq03417vrJX"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Y6FxglsvrJY"},"outputs":[],"source":["TRAINING = True\n"]},{"cell_type":"code","source":["training_dataset = 'TREC-TR'"],"metadata":{"id":"dTJXJnoLm7I2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-O9mQRL1vrJY"},"source":["#### sort topics by target location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmCjOYmPvrJY"},"outputs":[],"source":["\n","\n","dataset_name = 'TREC-TR'\n","\n","qrels = \"data/qrels/TREC_TR_Training_qrels.txt\"\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/tr_training_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2UDM_l2LvrJY"},"outputs":[],"source":["topics_info = []\n","\n","for t in topics_list:\n","  topic_id, n_docs, n_rel, prev, target_location = load_topic_target_location(t,target_recall)\n","  print(topic_id, n_docs, n_rel, round(prev,3), target_location)\n","  topics_info.append([topic_id, n_docs, n_rel, prev, target_location])\n","\n","topics_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iffEghQyvrJZ"},"outputs":[],"source":["\n","df = pd.DataFrame(topics_info, columns=['topic_id', 'n_docs', 'n_rel', 'prev', 'target_location'])\n","df = df.sort_values(by=['target_location'])\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkDuPxr9vrJZ"},"outputs":[],"source":["sorted_target_loc_topics = list(df['topic_id'])\n","sorted_target_loc_topics"]},{"cell_type":"markdown","metadata":{"id":"QQB57TljvrJZ"},"source":["####ordered topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWX8tKV-vrJa"},"outputs":[],"source":["TRAINING = True\n","\n","SELECTED_TOPICS_ORDERERD = sorted_target_loc_topics\n","SELECTED_TOPICS_ORDERERD_INDEX = 0\n","# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","train_size = len(topics_list)\n","vec_env_train = vec_env"]},{"cell_type":"markdown","metadata":{"id":"hbFV4gU7vrJa"},"source":["####  PPO"]},{"cell_type":"code","source":["\n","\n","tb_log_name = model_name+\"_\"+training_dataset+\"_ppo_gma_\"+str(gamma)+\"_nsteps\"+str(n_steps)+\"_btch\"+str(batch_size)+\"_timesteps_\"+str(total_timesteps)+ \"_ent_coef\"+str(ent_coef)+ learning_rate_type +\"_n_epochs\"+str(n_epochs)+\"_target\"+str(target_recall)\n","\n","model = PPO(\n","    policy = 'MlpPolicy',\n","    env = vec_env_train,\n","    n_steps = n_steps,\n","    batch_size = batch_size,\n","    n_epochs = n_epochs,\n","    gamma = gamma,\n","    gae_lambda = 0.98,\n","    ent_coef = ent_coef,\n","    verbose=1,\n","    learning_rate = learning_rate,\n","    seed=0,\n","    tensorboard_log= tensorboard_log)\n","\n","model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n","\n","\n","model.save(tensorboard_log+'model_'+tb_log_name)\n","\n","\n"],"metadata":{"id":"VMzb_RSbvrJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir \"$tensorboard_log\"\n"],"metadata":{"id":"-97Qxzw6vrJb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testing"],"metadata":{"id":"6POEsMmrvrJd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ld0qV5DvrJd"},"outputs":[],"source":["dataset_name = 'TREC-TR'\n","\n","\n","\n","\n","qrels = \"data/qrels/TREC_TR_Test_qrels.txt\" # use the same qrel list as their rankings\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/tr_test_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQiLKjw4vrJd"},"outputs":[],"source":["# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvq16rWzvrJe"},"outputs":[],"source":["test_size = len(topics_list)\n","vec_env_test = vec_env"]},{"cell_type":"markdown","metadata":{"id":"d5HXnpXXxHsh"},"source":["#### TAR Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXHH6-RuxHsw"},"outputs":[],"source":["\n","df = pd.DataFrame()\n","df_all_runs = pd.DataFrame()\n","\n","for run in range(total_runs):\n","\n","  # Test the trained agent\n","  vec_env_test = vec_env\n","  obs = vec_env_test.reset()\n","  test_steps = 100\n","\n","\n","  n_env = test_size\n","  agent=0\n","  target=0\n","  agent_vector=[]\n","  terminal_observation=[]\n","\n","  topics = []\n","  recalls = []\n","  costs=[]\n","  e_costs = []\n","  reliabilities = []\n","  rewards = []\n","  distances = []\n","  differences = []\n","  targets = []\n","  run_cnts = []\n","\n","  for eID in range(test_size):\n","\n","    env = vec_env_test.envs[eID]\n","    obs, info = env.reset()\n","\n","    for step in range(test_steps):\n","      action, _ = model.predict(obs, deterministic=False) # predict all next steps\n","      obs, reward, done, trun,info = env.step(action)\n","\n","\n","      if done or trun:\n","                  topic_id = info['topic_id']\n","                  recall = info['recall']\n","                  cost = info['cost']\n","                  e_cost =  ((info['agent'] - info['target']) / (100-info['target']))\n","                  distance = info['distance']\n","\n","                  agent = info['agent']\n","                  target = info['target']\n","                  agent_vector = info['agent_vector']\n","                  terminal_observation = info['terminal_observation']\n","\n","                  difference = target_recall - recall\n","\n","                  reliability = 1 if recall >= target_recall else 0\n","                  topics.append(topic_id)\n","                  recalls.append(recall)\n","                  costs.append(cost)\n","                  e_costs.append(e_cost)\n","                  reliabilities.append(reliability)\n","                  rewards.append(reward)\n","                  distances.append(distance)\n","                  targets.append(target)\n","                  run_cnts.append(run)\n","                  differences.append(difference)\n","\n","                  df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n","                  columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n","\n","                  df = pd.concat([df_tmp])\n","\n","                  df.groupby('Topic').mean()\n","\n","                  break\n","\n","  display(df)\n","  df.groupby('Topic').mean()\n","  df_all_runs = pd.concat([df_all_runs, df])\n","\n","df_all_runs['Model'] = model_name\n","df_all_runs['Model_settings'] = tb_log_name\n","df_all_runs['Target_Recall'] = target_recall\n","df_all_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LG6WOQPxHsw"},"outputs":[],"source":["display(df_all_runs.groupby('Topic').mean())\n","display(df_all_runs.groupby('Topic').std())\n"]},{"cell_type":"markdown","metadata":{"id":"kDrsd0SsxHsx"},"source":["#### df_all_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4p4LDx6wxHsx"},"outputs":[],"source":["\n","df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n","\n","\n","display(df_all_targets)\n","\n","df_all_targets.describe()"]},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))\n","display(df_all_targets.groupby(['Target_Recall','Dataset']).std().round(3))"],"metadata":{"id":"DGDWqN3HxHsy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15Z-d0Wf94UE"},"source":["##RCV1"]},{"cell_type":"markdown","metadata":{"id":"4MUDYu6s94UN"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANsBkV9094UR"},"outputs":[],"source":["TRAINING = True\n"]},{"cell_type":"code","source":["training_dataset = 'RCV1'"],"metadata":{"id":"C1shTQoJnF9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQtwuarE94UO"},"source":["#### sort topics by target location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-UtBjXC94US"},"outputs":[],"source":["# LOAD RUN DATA\n","def load_run_data(run):\n","  run_fname = os.path.join(DIR, run)\n","  with open(run_fname, 'r', encoding='utf-8-sig') as infile: # resolve file encoding problem !!\n","    run_data = infile.readlines()\n","  doc_rank_dic = make_rank_dic(run_data)  # make dictionary of ranked docids for each queryid\n","  rank_rel_dic = make_rank_rel_dic(query_rel_dic,doc_rank_dic) # make dic of list relevances of ranked docs for each queryid\n","\n","  #return doc_rank_dic, rank_rel_dic, rank_text_dic\n","  return doc_rank_dic, rank_rel_dic\n","\n","\n","\n","\n","dataset_name = 'RCV1'\n","\n","qrels = \"data/qrels/rcv1_qrels_selected_wo45_0.2.txt\" # use the same qrel list as their rankings\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/RCV1_test_20wo45_ranking.txt\"\n","run = \"data/rankings/temp/RCV1_test_20wo45_ranking_utf8_2.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)###\n","\n","\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs"]},{"cell_type":"code","source":["# only selected 1st level topics\n","topics_list = ['C151', 'C171', 'C181', 'C311', 'C331', 'C411', 'E121', 'E131', 'E141', 'E211', 'E311', 'E411', 'E511', 'G151', 'M131', 'M141']"],"metadata":{"id":"XAaFlDz-SvfG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hx5HB76v94US"},"outputs":[],"source":["topics_info = []\n","\n","for t in topics_list:\n","  topic_id, n_docs, n_rel, prev, target_location = load_topic_target_location(t,target_recall)\n","  print(topic_id, n_docs, n_rel, round(prev,3), target_location)\n","  topics_info.append([topic_id, n_docs, n_rel, prev, target_location])\n","\n","topics_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSt6_4P194US"},"outputs":[],"source":["# import pandas as pd\n","import pandas as pd\n","\n","\n","df = pd.DataFrame(topics_info, columns=['topic_id', 'n_docs', 'n_rel', 'prev', 'target_location'])\n","df = df.sort_values(by=['target_location'])\n","#df = df.sort_values(by=['target_location'],ascending=False)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4H6dEaeY94US"},"outputs":[],"source":["sorted_target_loc_topics = list(df['topic_id'])\n","sorted_target_loc_topics"]},{"cell_type":"markdown","metadata":{"id":"iAwxbZqu94US"},"source":["####ordered topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyK4_aDC94US"},"outputs":[],"source":["TRAINING = True\n","\n","SELECTED_TOPICS_ORDERERD = sorted_target_loc_topics\n","SELECTED_TOPICS_ORDERERD_INDEX = 0\n","# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","train_size = len(topics_list)\n","vec_env_train = vec_env"]},{"cell_type":"markdown","metadata":{"id":"EC2NS_xl94UT"},"source":["#### PPO"]},{"cell_type":"code","source":["\n","\n","tb_log_name = model_name+\"_\"+training_dataset+\"_ppo_gma_\"+str(gamma)+\"_nsteps\"+str(n_steps)+\"_btch\"+str(batch_size)+\"_timesteps_\"+str(total_timesteps)+ \"_ent_coef\"+str(ent_coef)+ learning_rate_type +\"_n_epochs\"+str(n_epochs)+\"_target\"+str(target_recall)\n","\n","model = PPO(\n","    policy = 'MlpPolicy',\n","    env = vec_env_train,\n","    n_steps = n_steps,\n","    batch_size = batch_size,\n","    n_epochs = n_epochs,\n","    gamma = gamma,\n","    gae_lambda = 0.98,\n","    ent_coef = ent_coef,\n","    verbose=1,\n","    learning_rate = learning_rate,\n","    seed=0,\n","    tensorboard_log= tensorboard_log)\n","\n","model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n","\n","\n","model.save(tensorboard_log+'model_'+tb_log_name)\n","\n","\n"],"metadata":{"id":"srSCLKsz94UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir \"$tensorboard_log\"\n"],"metadata":{"id":"dxCvKqUP94UT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testing"],"metadata":{"id":"USBIplgW94UU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7D-UQ1-94UU"},"outputs":[],"source":["dataset_name = 'RCV1'\n","\n","\n","qrels = \"data/qrels/rcv1_qrels_selected_45_0.2.txt\" # use the same qrel list as their rankings\n","\n","\n","qrel_fname, query_rel_dic = load_rel_data(qrels)\n","print(\"Number of topics:\", len(query_rel_dic))\n","\n","run = \"data/rankings/RCV1_selected_45_0.2_ranking.txt\"\n","\n","doc_rank_dic, rank_rel_dic = load_run_data(run)\n","\n","topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zlf1Cnwu94UU"},"outputs":[],"source":["# Instantiate the vec env\n","\n","#random topic selection for each env instance\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n","\n","vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n","\n","SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvyYvFdt94UU"},"outputs":[],"source":["test_size = len(topics_list)\n","vec_env_test = vec_env"]},{"cell_type":"markdown","metadata":{"id":"pTai41gixQNr"},"source":["#### TAR Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1gGWd5uxQNs"},"outputs":[],"source":["\n","df = pd.DataFrame()\n","df_all_runs = pd.DataFrame()\n","\n","for run in range(total_runs):\n","\n","  # Test the trained agent\n","  vec_env_test = vec_env\n","  obs = vec_env_test.reset()\n","  test_steps = 100\n","\n","\n","  n_env = test_size\n","  agent=0\n","  target=0\n","  agent_vector=[]\n","  terminal_observation=[]\n","\n","  topics = []\n","  recalls = []\n","  costs=[]\n","  e_costs = []\n","  reliabilities = []\n","  rewards = []\n","  distances = []\n","  differences = []\n","  targets = []\n","  run_cnts = []\n","\n","  for eID in range(test_size):\n","\n","    env = vec_env_test.envs[eID]\n","    obs, info = env.reset()\n","\n","    for step in range(test_steps):\n","      action, _ = model.predict(obs, deterministic=False) # predict all next steps\n","      obs, reward, done, trun,info = env.step(action)\n","\n","\n","      if done or trun:\n","                  topic_id = info['topic_id']\n","                  recall = info['recall']\n","                  cost = info['cost']\n","                  e_cost =  ((info['agent'] - info['target']) / (100-info['target']))\n","                  distance = info['distance']\n","\n","                  agent = info['agent']\n","                  target = info['target']\n","                  agent_vector = info['agent_vector']\n","                  terminal_observation = info['terminal_observation']\n","\n","                  difference = target_recall - recall\n","\n","                  reliability = 1 if recall >= target_recall else 0\n","                  topics.append(topic_id)\n","                  recalls.append(recall)\n","                  costs.append(cost)\n","                  e_costs.append(e_cost)\n","                  reliabilities.append(reliability)\n","                  rewards.append(reward)\n","                  distances.append(distance)\n","                  targets.append(target)\n","                  run_cnts.append(run)\n","                  differences.append(difference)\n","\n","                  df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n","                  columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n","\n","                  df = pd.concat([df_tmp])\n","\n","                  df.groupby('Topic').mean()\n","\n","                  break\n","\n","  display(df)\n","  df.groupby('Topic').mean()\n","  df_all_runs = pd.concat([df_all_runs, df])\n","\n","df_all_runs['Model'] = model_name\n","df_all_runs['Model_settings'] = tb_log_name\n","df_all_runs['Target_Recall'] = target_recall\n","df_all_runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClA0f1_MxQNs"},"outputs":[],"source":["display(df_all_runs.groupby('Topic').mean())\n","display(df_all_runs.groupby('Topic').std())\n"]},{"cell_type":"markdown","metadata":{"id":"Co2EKUmQxQNt"},"source":["#### df_all_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0I7o7uQvxQNt"},"outputs":[],"source":["\n","df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n","\n","\n","display(df_all_targets)\n","\n","df_all_targets.describe()"]},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))\n","display(df_all_targets.groupby(['Target_Recall','Dataset']).std().round(3))"],"metadata":{"id":"NShx1II4xQNt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### vis all datasets"],"metadata":{"id":"nOkqi-tO94UW"}},{"cell_type":"code","source":["display(df_all_targets.groupby(['Target_Recall','Dataset']).mean().round(3))"],"metadata":{"id":"QScQU4_494UW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1iMzkiuvrJj"},"outputs":[],"source":["(df_all_targets[['Target_Recall', 'Dataset', 'Recall' , 'Reliability', 'Cost', 'e-Cost']].groupby(['Target_Recall','Dataset']).mean().round(3)).to_latex()\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["y00RfkU5gl3e","pEsAU3iFchK7","AjNCmL-zV_Xp","HkcMI0zCV_Xr","nEsMxqiPGBwD","kfzuy5BvGBwJ"],"provenance":[{"file_id":"1udDQgbOMm7LmCdhfADeKeKyDSwRv8NCD","timestamp":1692623348469}],"toc_visible":true,"machine_shape":"hm","gpuType":"T4","mount_file_id":"1VInyjg3LeGBWUtsIvknO5d8qNamBy3uf","authorship_tag":"ABX9TyMkL1AWPqK+Rxr7Jr2qOmga"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}